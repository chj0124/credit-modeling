#+TITLE: 线性模型

* 分类器
** 输出离散值就是分类？输出连续值就是回归？错！
** 分类与回归
* 感知机的意义
** 初识分类器
** Hebbian 原则
*** 粗暴下降
*** 不均衡样本
* 一个简单数据集
** Target
** Feature
* 感知机结构
** 输入与偏置值
** 权值向量
** 激活函数
** 损失函数
* 训练过程
** 线性组合
权值向量与输入样本做个简单的点积，得到结果 u
** 激活函数
u 进入激活函数 f，得到感知机输出 y = f(u)
** 计算误差
计算感知机输出 y 与真实值 t 的误差:

Error = E = t - y

** 权值往误差减小的方向移动
~为什么误差定义为 t - y 而不是 y - t 呢？~

* 自己写一个感知机对象

* 梯度下降
** 梯度下降为什么有效
函数

\[
f(x, y) = x^2 + y^2
\]

的梯度为：

\[
\nabla{f} = (\frac{\partial{f}}{\partial{x}}, \frac{\partial{f}}{\partial{y}}) = (2x, 2y)
\]

损失函数 $$ S = f(w, b)$$ 的图像(即误差曲面)也是一个凹函数，因次权值和偏置值每一次训练的时候按照负梯度方向来更新可以使总误差减少得最快。

