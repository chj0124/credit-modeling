#+TITLE: 决策树及其衍生模型

* 分类树与回归树
[[./tree.png]]
* 分裂原则
** 信息熵
信息熵表示的是不确定度。均匀分布时，不确定度最大，此时熵就最大。当选择某个特征对数据集进行分类时，分类后的数据集信息熵会比分类前的小，其差值表示为信息增益。信息增益可以衡量某个特征对分类结果的影响大小。

** gini 不纯度

\begin{huge}
\[
w^Tx = p
\] 
\end{huge}

** 贪心
训练一棵最优的决策树是一个完全 NP 问题。因此, 实际应用时决策树的训练采用启发式搜索算法例如 贪心算法 来达到局部最优。这样的算法没办法得到最优的决策树。

* 步骤
** 选择最好的属性
** 选择分裂点
** 剪枝
* cart 离散化原理
* 几种算法
** ID3
** C4.5

比起 ID3，C4.5 通过使用信息增益率来避免过拟合。

C4.5中，增加的熵要除以分割太细的代价，这个比值叫做信息增益率，显然分割太细分母增加，信息增益率会降低。

** C5.0
** CART (Classification And Regression Tree)
- 使用 gini 不纯度
- 剪枝
* 手写决策树的前置知识
** 递归函数
** 树状数据结构的存储和遍历
